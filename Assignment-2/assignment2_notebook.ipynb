{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36df033e",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087cbc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import cv2\n",
    "import py360convert\n",
    "import re\n",
    "import folium\n",
    "import plotly.express as px\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "import math\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from math import sqrt\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335e9ca9",
   "metadata": {},
   "source": [
    "We firstly inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cce4c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do a first inspection, i.e. do the images have the same size, are we able to detect the black frames, etc.?\n",
    "image_folder = 'C:/Users/Nutzer/Downloads/images(1)/images'\n",
    "\n",
    "def inspect_images(image_root, num_images_per_folder=3):\n",
    "    for subfolder in sorted(os.listdir(image_root)):\n",
    "        subfolder_path = os.path.join(image_root, subfolder)\n",
    "        if not os.path.isdir(subfolder_path):\n",
    "            continue\n",
    "\n",
    "        print(f\"Inspecting images from folder: '{subfolder}'\")\n",
    "        images = [f for f in os.listdir(subfolder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "        print(f\"  Total images: {len(images)}\")\n",
    "\n",
    "        # Sample image inspection\n",
    "        for img_name in images[:num_images_per_folder]:\n",
    "            img_path = os.path.join(subfolder_path, img_name)\n",
    "            with Image.open(img_path) as img:\n",
    "                width, height = img.size\n",
    "                np_img = np.array(img)\n",
    "                img_mean_pixel_value = np.mean(np_img)\n",
    "\n",
    "                # Check for black frame (at right edge)\n",
    "                right_edge = np_img[:, -1, :]\n",
    "                right_edge_mean = np.mean(right_edge)\n",
    "\n",
    "                print(f\"Image: {img_name}\")\n",
    "                print(f\"Dimensions: {width}px (width) × {height}px (height)\")\n",
    "                print(f\"Mean Pixel Value: {img_mean_pixel_value:.2f}\")\n",
    "                if right_edge_mean < 10:\n",
    "                    print(f\"Possible black frame detected {right_edge_mean:.2f})\")\n",
    "                else:\n",
    "                    print(f\"No black frame detected {right_edge_mean:.2f})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    inspect_images(image_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e21a872",
   "metadata": {},
   "source": [
    "The images are quite big, we downsize them a little. We detected black frames that have to be removed or images that are entirely black."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6db426c",
   "metadata": {},
   "source": [
    "We resize once and take out black borders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f64657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dir = 'C:/Users/Nutzer/Downloads/images(1)/images'\n",
    "processed_dir = 'processed_images_final'\n",
    "resize_dim_final = (4096, 2048) \n",
    "\n",
    "# resize function\n",
    "def resize_final(img):\n",
    "    return img.resize(resize_dim_final, Image.LANCZOS)\n",
    "\n",
    "# crop function\n",
    "def remove_black_borders(img, threshold=10):\n",
    "    img_np = np.array(img)\n",
    "    gray = np.mean(img_np, axis=2)\n",
    "    mask = gray > threshold\n",
    "    coords = np.argwhere(mask)\n",
    "\n",
    "    if coords.size == 0:\n",
    "        # fully black = just return image \n",
    "        print(\"Image fully black\")\n",
    "        return img \n",
    "\n",
    "    y0, x0 = coords.min(axis=0)\n",
    "    y1, x1 = coords.max(axis=0) + 1\n",
    "    return img.crop((x0, y0, x1, y1))\n",
    "\n",
    "# Processing loop\n",
    "panorama_images, labels = [], []\n",
    "\n",
    "for country in os.listdir(original_dir):\n",
    "    country_path = os.path.join(original_dir, country)\n",
    "    if not os.path.isdir(country_path):\n",
    "        continue\n",
    "\n",
    "    for img_name in os.listdir(country_path):\n",
    "        if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            img_path = os.path.join(country_path, img_name)\n",
    "\n",
    "            img = Image.open(img_path)\n",
    "            img_resized = resize_final(img)\n",
    "            img_cropped = remove_black_borders(img_resized)\n",
    "\n",
    "            # Save directly\n",
    "            final_country_dir = os.path.join(processed_dir, country)\n",
    "            os.makedirs(final_country_dir, exist_ok=True)\n",
    "            final_img_path = os.path.join(final_country_dir, img_name)\n",
    "            img_cropped.save(final_img_path, 'JPEG', quality=85)\n",
    "\n",
    "            panorama_images.append(final_img_path)\n",
    "            labels.append(country)\n",
    "\n",
    "            print(f\"Saved: {country}/{img_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917e47ba",
   "metadata": {},
   "source": [
    "Image Transformation: The images are equirectangular. Thus, we can extract 4 perspectives from one picture. We do that using the cv2 and py360convert libraries using yaw angles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac64ee5",
   "metadata": {},
   "source": [
    "We extract 4 views per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776d53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"processed_images_final\"\n",
    "output_dir = \"processed_images_final_perspectives\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# dimensions, field-of-view, number of perspectives\n",
    "img_width, img_height = 1024, 1024)\n",
    "fov_deg = (90, 90)\n",
    "num_views = 4\n",
    "\n",
    "def extract_views(equi_img, num_views, fov_deg, out_hw):\n",
    "    yaw_angles = np.linspace(-180, 180, num_views, endpoint=False)\n",
    "    views = []\n",
    "    for yaw in yaw_angles:\n",
    "        perspective = py360convert.e2p(\n",
    "            equi_img,\n",
    "            fov_deg=fov_deg,\n",
    "            u_deg=yaw,\n",
    "            v_deg=0,\n",
    "            out_hw=out_hw,\n",
    "            mode='bilinear'\n",
    "        )\n",
    "        views.append(perspective)\n",
    "    return views\n",
    "\n",
    "# apply to each country folder\n",
    "for country in os.listdir(input_dir):\n",
    "    country_path = os.path.join(input_dir, country)\n",
    "    if not os.path.isdir(country_path):\n",
    "        continue\n",
    "\n",
    "    # output directory\n",
    "    output_country_path = os.path.join(output_dir, country)\n",
    "    os.makedirs(output_country_path, exist_ok=True)\n",
    "\n",
    "    # process each image file in country folder\n",
    "    for img_name in os.listdir(country_path):\n",
    "        if not img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            continue\n",
    "\n",
    "        input_img_path = os.path.join(country_path, img_name)\n",
    "        equi_img = cv2.imread(input_img_path)\n",
    "        if equi_img is None:\n",
    "            print(f\"Warning: Could not read image {input_img_path}\")\n",
    "            continue\n",
    "\n",
    "        # BGR to RGB for processing\n",
    "        equi_img = cv2.cvtColor(equi_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # extract perspective views from equirectangular image\n",
    "        views = extract_views(equi_img, num_views, fov_deg, (img_height, img_width))\n",
    "\n",
    "        # save each perspective view -> filename that starts with the original name\n",
    "        for i, view in enumerate(views):\n",
    "            base_name, ext = os.path.splitext(img_name)\n",
    "            new_filename = f\"{base_name}_view_{i+1}.jpg\"\n",
    "            save_path = os.path.join(output_country_path, new_filename)\n",
    "            \n",
    "            # Convert RGB back to BGR for cv2.imwrite\n",
    "            view_bgr = cv2.cvtColor(view, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(save_path, view_bgr)\n",
    "\n",
    "        # example to check\n",
    "        print(f\"Processed {img_name} in {country} -> saved {num_views} perspective views.\")\n",
    "\n",
    "print(\"All images processed and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa78a710",
   "metadata": {},
   "source": [
    "Inspecting Corrupted Images: When going through the images manually, we detected some entirely black images. As they provide no useful information for learning and prediction, they should be removed from the entire dataset. Additionally, we saw some images with an odd color spectrum that likely came from tunnels. We want to find out how many those are to make a decision on how to deal with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05083a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"processed_images_final_perspectives\"\n",
    "\n",
    "# load an image and check whether it's abnormal\n",
    "def check_abnormal(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None, \"error\"\n",
    "    \n",
    "    # convert again from BGR to RGB for processing\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # mean color value over all pixels (per channel)\n",
    "    mean_colors = np.mean(img_rgb, axis=(0, 1))\n",
    "    red, green, blue = mean_colors\n",
    "\n",
    "    # check for completely black images\n",
    "    if np.all(mean_colors < 10):\n",
    "        return img_rgb, \"Completely black\"\n",
    "\n",
    "    # check for tunnel pictures (heuristic: red is very high, others are low)\n",
    "    if red > 200 and green < 150 and blue < 150:\n",
    "        return img_rgb, \"Tunnel\"\n",
    "\n",
    "    return None, None \n",
    "\n",
    "# loop over all images in the data\n",
    "for country in os.listdir(dir):\n",
    "    country_path = os.path.join(dir, country)\n",
    "    if not os.path.isdir(country_path):\n",
    "        continue\n",
    "\n",
    "    for img_name in os.listdir(country_path):\n",
    "        image_path = os.path.join(country_path, img_name)\n",
    "        abnormal_img, reason = check_abnormal(image_path)\n",
    "        \n",
    "        # if an abnormal image is found\n",
    "        if abnormal_img is not None:\n",
    "            print(f\"abnormal image found: {image_path} - reason: {reason}\")\n",
    "\n",
    "        # because we found only 8 pictures with tunnels (2 locations), \n",
    "        # we will delete them globally as they won't contribute to model training and could influence it in a bad way\n",
    "        if abnormal_img is not None:\n",
    "            os.remove(image_path)\n",
    "            print(f\"Deleted {image_path} - {reason}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e198781",
   "metadata": {},
   "source": [
    "To get an overview, we explore the positions of the places portrayed via a map. Additionally, we check whether all the locations are actually in the 13 countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04670cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have filenames like 1741691006_-30.9927065_-68.8548332_view_1.jpg that contain the coordinates\n",
    "pattern = re.compile(r'(\\d+)_(-?\\d+\\.\\d+)_(-?\\d+\\.\\d+)_view_(\\d+)(?:\\.jpg)?$')\n",
    "\n",
    "coords = []\n",
    "\n",
    "# check all subdirectories and files\n",
    "for subdir, dirs, files in os.walk(dir):\n",
    "    for filename in files:\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            timestamp, lat, lon, view = match.groups()\n",
    "            coords.append((float(lat), float(lon)))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "# remove duplicate coordinates since each location has 4 views\n",
    "unique_coords = list(set(coords))\n",
    "\n",
    "if not unique_coords:\n",
    "    print(\"No coordinates extracted.\")\n",
    "else:\n",
    "\n",
    "    # dataframe with unique coordinates\n",
    "    df = pd.DataFrame(unique_coords, columns=['lat', 'lon'])\n",
    "    print(\"coordinates:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # interactive map with plotly express, save as html file \n",
    "    fig = px.scatter_geo(\n",
    "        df,\n",
    "        lat='lat',\n",
    "        lon='lon',\n",
    "        title=\"Image Locations Map\",\n",
    "        projection=\"natural earth\",\n",
    "        hover_name=\"lat\"\n",
    "    )\n",
    "\n",
    "    fig.update_traces(marker=dict(color='red', size=5))\n",
    "    fig.write_html(\"map.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1265c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we detected some suspicious markers in the Indian Ocean. Investigate points where lat < -10 and lon between 50 and 100.\n",
    "df_sus = df[(df['lat'] < -10) & (df['lon'] > 50) & (df['lon'] < 100)]\n",
    "print(\"sus coordinates:\")\n",
    "print(df_sus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c31a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate suspicious coordinates (-> probably belong to France, e.g. La Reunion)\n",
    "# store tuples of latitude, longitude, full_file_path\n",
    "coords_with_file = []\n",
    "\n",
    "# check all images\n",
    "for subdir, dirs, files in os.walk(dir):\n",
    "    for filename in files:\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            timestamp, lat, lon, view = match.groups()\n",
    "            full_path = os.path.join(subdir, filename)\n",
    "            coords_with_file.append((float(lat), float(lon), full_path))\n",
    "\n",
    "# dataframe \n",
    "df = pd.DataFrame(coords_with_file, columns=['lat', 'lon', 'filepath'])\n",
    "\n",
    "# suspicious coordinates:\n",
    "suspicious_coords = [\n",
    "    (-21.058772, 55.368674),\n",
    "    (-21.221322, 55.680430),\n",
    "    (-21.232792, 55.667724)\n",
    "]\n",
    "\n",
    "# tolerance for floating point precision issues\n",
    "def is_close(row, coord, tol=1e-6):\n",
    "    return (abs(row['lat'] - coord[0]) < tol) and (abs(row['lon'] - coord[1]) < tol)\n",
    "\n",
    "# print the corresponding files for each suspicious coordinate\n",
    "for coord in suspicious_coords:\n",
    "    filtered = df[df.apply(lambda row: is_close(row, coord), axis=1)]\n",
    "    print(\"\\nsuspicious coordinate {}:\".format(coord))\n",
    "    if filtered.empty:\n",
    "        print(\"no files found\")\n",
    "    else:\n",
    "        print(filtered[['filepath']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb692b04",
   "metadata": {},
   "source": [
    "Note: Those pictures have to be treated as outliers. The vegetation might be very different to those of the rest of France and, more important, if we aim to predict coordinates, 3 distinct locations for one region are not enough to build the model on. We assume that the purpose of the project is to make predictions about locations in the mainland of France which is why we delete the images from La Réunion, treating them as flaws in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0098524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete suspicious files\n",
    "for subdir, dirs, files in os.walk(dir):\n",
    "    for filename in files:\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            timestamp, lat_str, lon_str, view = match.groups()\n",
    "            lat, lon = float(lat_str), float(lon_str)\n",
    "            file_coord = (lat, lon)\n",
    "\n",
    "            # check again\n",
    "            if any(is_close(file_coord, sc) for sc in suspicious_coords):\n",
    "                full_path = os.path.join(subdir, filename)\n",
    "                print(f\"deleted {full_path}\")\n",
    "                os.remove(full_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db32fae",
   "metadata": {},
   "source": [
    "# Splitting the data and exploring training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b593439",
   "metadata": {},
   "source": [
    "We Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d121d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"final_dataset/train\"\n",
    "val_dir = \"final_dataset/validation\"\n",
    "test_dir = \"final_dataset/test\"\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# split ratios: 70% training, 15% validation, 15% test\n",
    "first_split_ratio = 0.3  # 30% for temporary set (val + test)\n",
    "second_split_ratio = 0.5  # split temp equally into validation and test\n",
    "\n",
    "# every folder with countries\n",
    "for country in os.listdir(dir):\n",
    "    country_input_path = os.path.join(dir, country)\n",
    "    if not os.path.isdir(country_input_path):\n",
    "        continue\n",
    "\n",
    "    # list images \n",
    "    images = [f for f in os.listdir(country_input_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    if not images:\n",
    "        continue\n",
    "\n",
    "    # 1st split: training vs. temporary (val+test)\n",
    "    train_imgs, temp_imgs = train_test_split(images, test_size=first_split_ratio, random_state=42)\n",
    "    \n",
    "    # 2nd split: split temporary set equally into validation and test\n",
    "    val_imgs, test_imgs = train_test_split(temp_imgs, test_size=second_split_ratio, random_state=42)\n",
    "    \n",
    "    # output folders for this country in train, validation, and test directories\n",
    "    country_train_dir = os.path.join(train_dir, country)\n",
    "    country_val_dir = os.path.join(val_dir, country)\n",
    "    country_test_dir = os.path.join(test_dir, country)\n",
    "    os.makedirs(country_train_dir, exist_ok=True)\n",
    "    os.makedirs(country_val_dir, exist_ok=True)\n",
    "    os.makedirs(country_test_dir, exist_ok=True)\n",
    "    \n",
    "    # copy training images\n",
    "    for img in train_imgs:\n",
    "        src = os.path.join(country_input_path, img)\n",
    "        dst = os.path.join(country_train_dir, img)\n",
    "        shutil.copy(src, dst)\n",
    "    \n",
    "    # copy validation images\n",
    "    for img in val_imgs:\n",
    "        src = os.path.join(country_input_path, img)\n",
    "        dst = os.path.join(country_val_dir, img)\n",
    "        shutil.copy(src, dst)\n",
    "    \n",
    "    # copy test images\n",
    "    for img in test_imgs:\n",
    "        src = os.path.join(country_input_path, img)\n",
    "        dst = os.path.join(country_test_dir, img)\n",
    "        shutil.copy(src, dst)\n",
    "    \n",
    "    print(f\"folder '{country}': {len(train_imgs)} train, {len(val_imgs)} validation, {len(test_imgs)} test images\")\n",
    "\n",
    "print(\"successfully split into train, validation, and test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad01a3f",
   "metadata": {},
   "source": [
    "We inspect the training set: we look at the number of images per country in the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b1a4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of images per country and portray samples\n",
    "# seaborn style\n",
    "sns.set(style=\"whitegrid\", context=\"talk\", palette=\"viridis\")\n",
    "\n",
    "train_dir = \"final_dataset/train\"\n",
    "\n",
    "# dataframe with the number of images per country\n",
    "data = []\n",
    "for country in os.listdir(train_dir):\n",
    "    country_path = os.path.join(train_dir, country)\n",
    "    if os.path.isdir(country_path):\n",
    "        images = [f for f in os.listdir(country_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        data.append({\"country\": country, \"count\": len(images)})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# bar plot with n images per country\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x=\"country\", y=\"count\", data=df)\n",
    "plt.title(\"Number of Training Images per Country\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# add sample image for each country\n",
    "countries = df['country'].tolist()\n",
    "n = len(countries)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n, figsize=(3 * n, 4))\n",
    "\n",
    "for ax, country in zip(axes, countries):\n",
    "    country_path = os.path.join(train_dir, country)\n",
    "    images = [os.path.join(country_path, f) for f in os.listdir(country_path)\n",
    "              if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    if images:\n",
    "        sample_img_path = random.choice(images)\n",
    "        img = Image.open(sample_img_path)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(country)\n",
    "        ax.axis(\"off\")\n",
    "    else:\n",
    "        ax.set_visible(False)\n",
    "\n",
    "plt.suptitle(\"sample training images per country\", y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4855d3a4",
   "metadata": {},
   "source": [
    "The amount of images per country vary greatly, we want to have 1000 images per country in the training data which is why we do image augmentation: converting a PIL image to a tensor, apply augmentation layers, and then convert it back to a PIL image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eee3f7",
   "metadata": {},
   "source": [
    "We augment the training dataset to reach 1000 images per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a50d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n images per country in training data\n",
    "target_count = 1000\n",
    "\n",
    "# augmentation layers\n",
    "data_augmentation_layers = [\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "]\n",
    "\n",
    "def random_augmentation(pil_img):\n",
    "\n",
    "    # PIL image to array\n",
    "    img_array = img_to_array(pil_img)\n",
    "    img_tensor = tf.expand_dims(img_array, 0)\n",
    "    \n",
    "    # augmentation layer\n",
    "    for aug in data_augmentation_layers:\n",
    "        img_tensor = aug(img_tensor)\n",
    "    \n",
    "    # remove batch dimension\n",
    "    img_tensor = tf.squeeze(img_tensor, axis=0)\n",
    "\n",
    "    # convert back\n",
    "    augmented_pil = array_to_img(img_tensor)\n",
    "    return augmented_pil\n",
    "\n",
    "# process everything\n",
    "for country in os.listdir(train_dir):\n",
    "    country_path = os.path.join(train_dir, country)\n",
    "    if not os.path.isdir(country_path):\n",
    "        continue\n",
    "\n",
    "    # list of all files\n",
    "    image_files = [f for f in os.listdir(country_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    current_count = len(image_files)\n",
    "    print(f\"Country '{country}' initially has {current_count} images.\")\n",
    "\n",
    "    augment_index = 1\n",
    "\n",
    "    # augment until the folder reaches the target count\n",
    "    while current_count < target_count:\n",
    "        for img_file in image_files:\n",
    "            if current_count >= target_count:\n",
    "                break\n",
    "            img_path = os.path.join(country_path, img_file)\n",
    "            pil_img = Image.open(img_path)\n",
    "\n",
    "            augmented_img = random_augmentation(pil_img)\n",
    "            base, ext = os.path.splitext(img_file)\n",
    "            new_filename = f\"{base}_aug{augment_index}{ext}\"\n",
    "            new_img_path = os.path.join(country_path, new_filename)\n",
    "            augmented_img.save(new_img_path, quality=85)\n",
    "            \n",
    "            current_count += 1\n",
    "            augment_index += 1\n",
    "        \n",
    "        # include newly generated images in list\n",
    "        image_files = [f for f in os.listdir(country_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    print(f\"'{country}' now has {current_count} images.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671db860",
   "metadata": {},
   "source": [
    "# Geocell Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c621b7a1",
   "metadata": {},
   "source": [
    "The goal is to have a model that is able to predict not only the country of an image but the coordinates of the place portrayed. When searching for a pretrained model, we found the PIGEON project of Lukas Haas (see report). \n",
    "\n",
    "The PIGEON model defines a PyTorch neural network model designed for predicting geographic locations from image data. In particular, the author constructed a model for geolocation prediction via geocell classification:\n",
    "The model predicts a location by classifying an image (or a set of images) into one of many predefined geographical cells (“geocells”). It loads the centroids of these cells from a CSV file and then uses a linear layer to convert image embeddings into a probability distribution over these geocells. The predicted location is determined by selecting the geocell with the highest probability.\n",
    "\n",
    "The geocell design will be the basis of our model. The plot already showed that the images aren’t uniformly spread over each country’s bounding box. A fixed grid is thus not the best choice. We do k-means clustering per-country."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e59dbf",
   "metadata": {},
   "source": [
    "We perform a K-means clustering method and find the best number of cluster per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9e94b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper to parse lat/lon and country from a filepath\n",
    "def parse_fp(fp):\n",
    "    fn = os.path.basename(fp)\n",
    "    base = os.path.splitext(fn)[0]\n",
    "    parts = base.split(\"_\")\n",
    "    lat, lon = float(parts[1]), float(parts[2])\n",
    "    segs = os.path.normpath(fp).split(os.sep)\n",
    "    cidx = segs.index(\"train\") + 1\n",
    "    country = segs[cidx]\n",
    "    return country, lat, lon\n",
    "\n",
    "# coords per country\n",
    "root = \"final_dataset/train\"\n",
    "coords_by_country = {}\n",
    "for dp, _, fns in os.walk(root):\n",
    "    for fn in fns:\n",
    "        if not fn.lower().endswith(\".jpg\"): continue\n",
    "        fp = os.path.join(dp, fn)\n",
    "        country, lat, lon = parse_fp(fp)\n",
    "        coords_by_country.setdefault(country, []).append((lat, lon))\n",
    "\n",
    "# elbow\n",
    "def detect_elbow(Ks, inertias):\n",
    "    x1, y1 = Ks[0], inertias[0]\n",
    "    x2, y2 = Ks[-1], inertias[-1]\n",
    "    denom = sqrt((y2 - y1)**2 + (x2 - x1)**2)\n",
    "    distances = []\n",
    "    for x0, y0 in zip(Ks, inertias):\n",
    "        num = abs((y2 - y1)*x0 - (x2 - x1)*y0 + x2*y1 - y2*x1)\n",
    "        distances.append(num / denom)\n",
    "    elbow_idx = int(np.argmax(distances))\n",
    "    return Ks[elbow_idx]\n",
    "\n",
    "# find best k via elbow and silhouette\n",
    "def find_best_k(coords, k_min=2, k_max=20):\n",
    "    inertias, silhouettes = [], []\n",
    "    Ks = list(range(k_min, min(k_max, len(coords)-1) + 1))\n",
    "    for K in Ks:\n",
    "        km = KMeans(n_clusters=K, random_state=0).fit(coords)\n",
    "        inertias.append(km.inertia_)\n",
    "        silhouettes.append(silhouette_score(coords, km.labels_) if K>1 else np.nan)\n",
    "\n",
    "    # plot\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(Ks, inertias, '-o', color='tab:blue', label='Inertia')\n",
    "    ax1.set_xlabel('K'); ax1.set_ylabel('Inertia', color='tab:blue')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(Ks, silhouettes, '-o', color='tab:red', label='Silhouette')\n",
    "    ax2.set_ylabel('Silhouette', color='tab:red')\n",
    "    plt.title('Elbow & Silhouette Analysis'); plt.show()\n",
    "\n",
    "    K_elbow      = detect_elbow(Ks, inertias)\n",
    "    K_silhouette = Ks[int(np.nanargmax(silhouettes))]\n",
    "\n",
    "    return K_elbow, K_silhouette\n",
    "\n",
    "# for all countries\n",
    "for country, coords in coords_by_country.items():\n",
    "    arr = np.array(coords)\n",
    "    max_k = min(40, len(arr)//10)\n",
    "    K_elbow, K_sil = find_best_k(arr, k_min=2, k_max=max_k)\n",
    "    print(f\"{country}: elbow K = {K_elbow}, silhouette K = {K_sil}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f770bec",
   "metadata": {},
   "source": [
    "The elbow‐Ks are all in a reasonably range (5–8) and the silhouette‐Ks sometimes collapse to very coarse values (e.g. 2 for France, 40 for Switzerland). We stick to the elbow picks for the final clustering. The elbow point reflects where adding clusters stops giving big gains in compactness, and that yields a useful spatial resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a5fa2e",
   "metadata": {},
   "source": [
    "Construct the geocells for each country and save it in the csv file. \n",
    "We do that for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f6ea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elbow k's\n",
    "country_to_K = {\n",
    "  \"argentina\":   6,\n",
    "  \"austria\":     7,\n",
    "  \"canada\":      7,\n",
    "  \"chile\":       7,\n",
    "  \"france\":      6,    \n",
    "  \"iceland\":     8,\n",
    "  \"italy\":       5,    \n",
    "  \"japan\":       7,\n",
    "  \"new_zealand\": 7,\n",
    "  \"norway\":      5,\n",
    "  \"peru\":        6,\n",
    "  \"switzerland\": 7,\n",
    "}\n",
    "\n",
    "# 1) rebuild train list\n",
    "records = []\n",
    "for dp, _, fns in os.walk(\"final_dataset/train\"):\n",
    "    for fn in fns:\n",
    "        if not fn.lower().endswith(\".jpg\"):\n",
    "            continue\n",
    "        fp = os.path.join(dp, fn)\n",
    "        base = os.path.splitext(fn)[0]\n",
    "        # filename format: timestamp_lat_lon_view_x\n",
    "        _, lat, lon, *_ = base.split(\"_\")\n",
    "        lat, lon = float(lat), float(lon)\n",
    "        # country folder right after 'train'\n",
    "        parts = os.path.normpath(fp).split(os.sep)\n",
    "        country = parts[parts.index(\"train\") + 1]\n",
    "        records.append({\n",
    "            \"filepath\": fp,\n",
    "            \"lat\": lat,\n",
    "            \"lon\": lon,\n",
    "            \"country\": country\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "print(\"Rebuilt raw train DataFrame:\", df.shape)\n",
    "\n",
    "# cluster per country\n",
    "train_cells = []\n",
    "centroids   = []\n",
    "\n",
    "for country, group in df.groupby(\"country\"):\n",
    "    coords = group[[\"lat\",\"lon\"]].to_numpy()\n",
    "    K = country_to_K[country]\n",
    "    km = KMeans(n_clusters=K, random_state=0).fit(coords)\n",
    "\n",
    "    # assign \n",
    "    g = group.copy()\n",
    "    g[\"local_id\"]   = km.labels_.astype(str)\n",
    "    g[\"geocell_id\"] = country + \"_\" + g[\"local_id\"]\n",
    "    train_cells.append(g)\n",
    "\n",
    "    # centroid dataframe\n",
    "    centers = pd.DataFrame(km.cluster_centers_, \n",
    "                           columns=[\"centroid_lat\",\"centroid_lon\"])\n",
    "    centers[\"local_id\"]   = centers.index.astype(str)\n",
    "    centers[\"geocell_id\"] = country + \"_\" + centers[\"local_id\"]\n",
    "    centers[\"country\"]    = country\n",
    "    centroids.append(centers)\n",
    "\n",
    "# results\n",
    "df_train_cells = pd.concat(train_cells, ignore_index=True)\n",
    "df_centroids   = pd.concat(centroids,   ignore_index=True)\n",
    "\n",
    "# label mapping\n",
    "df_train_cells[\"label\"] = df_train_cells[\"geocell_id\"]\\\n",
    "                               .astype(\"category\")\\\n",
    "                               .cat.codes\n",
    "df_centroids[\"label\"]    = df_centroids[\"geocell_id\"]\\\n",
    "                               .astype(\"category\")\\\n",
    "                               .cat.codes\n",
    "\n",
    "# save csv\n",
    "df_train_cells.to_csv(\"geocell_train.csv\", index=False)\n",
    "df_centroids  .to_csv(\"geocell_centroids.csv\", index=False)\n",
    "\n",
    "print(\"geocell_train.csv saved\", df_train_cells.label.nunique(), \"classes\")\n",
    "print(\"geocell_centroids.csv saved\", df_centroids.label.nunique(), \"centroids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0103e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for validation data: build lookup: country -> centroid array, geocell_id list, label list\n",
    "lookup = {}\n",
    "for country, g in df_centroids.groupby(\"country\"):\n",
    "    coords = g[[\"centroid_lat\",\"centroid_lon\"]].to_numpy()\n",
    "    ids    = g[\"geocell_id\"].tolist()\n",
    "    labels = g[\"label\"].tolist()\n",
    "    lookup[country] = (coords, ids, labels)\n",
    "\n",
    "# now process validation folder and assign each image to the nearest centroid\n",
    "val_recs = []\n",
    "for dp, _, fns in os.walk(\"final_dataset/validation\"):\n",
    "    for fn in fns:\n",
    "        if not fn.lower().endswith(\".jpg\"):\n",
    "            continue\n",
    "        fp = os.path.join(dp, fn)\n",
    "\n",
    "        # parse lat/lon from filename\n",
    "        base = os.path.splitext(fn)[0]\n",
    "        _, lat, lon, *_ = base.split(\"_\")\n",
    "        lat, lon = float(lat), float(lon)\n",
    "\n",
    "        # country from folder name\n",
    "        country = os.path.normpath(fp).split(os.sep)[-2]\n",
    "        \n",
    "        cents, ids, labels = lookup[country]\n",
    "        \n",
    "        # euclidean distance in lat/lon space\n",
    "        dists = np.linalg.norm(cents - np.array([lat, lon]), axis=1)\n",
    "        idx   = int(dists.argmin())\n",
    "        \n",
    "        val_recs.append({\n",
    "            \"filepath\":     fp,\n",
    "            \"country\":      country,\n",
    "            \"geocell_id\":   ids[idx],\n",
    "            \"label\":        labels[idx],\n",
    "            \"lat\":          lat,\n",
    "            \"lon\":          lon\n",
    "        })\n",
    "\n",
    "df_val = pd.DataFrame(val_recs)\n",
    "df_val.to_csv(\"geocell_val.csv\", index=False)\n",
    "print(\"val complete:\", df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df12859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for test data\n",
    "\n",
    "# test image to nearest centroid\n",
    "test_recs = []\n",
    "for dp, _, fns in os.walk(\"final_dataset/test\"):\n",
    "    for fn in fns:\n",
    "        if not fn.lower().endswith(\".jpg\"):\n",
    "            continue\n",
    "        fp = os.path.join(dp, fn)\n",
    "        base = os.path.splitext(fn)[0]\n",
    "        _, lat, lon, *_ = base.split(\"_\")\n",
    "        lat, lon = float(lat), float(lon)\n",
    "        country = os.path.normpath(fp).split(os.sep)[-2]\n",
    "\n",
    "        if country not in lookup:\n",
    "            print(f\"Warning: '{country}' not in centroids. Skipping {fp}.\")\n",
    "            continue\n",
    "\n",
    "        cents, ids, labels = lookup[country]\n",
    "        dists = np.linalg.norm(cents - np.array([lat, lon]), axis=1)\n",
    "        idx = int(dists.argmin())\n",
    "\n",
    "        test_recs.append({\n",
    "            \"filepath\":   fp,\n",
    "            \"country\":    country,\n",
    "            \"geocell_id\": ids[idx],\n",
    "            \"label\":      labels[idx],\n",
    "            \"lat\":        lat,\n",
    "            \"lon\":        lon\n",
    "        })\n",
    "\n",
    "df_test = pd.DataFrame(test_recs)\n",
    "df_test.to_csv(\"geocell_test.csv\", index=False)\n",
    "print(\"test complete:\", df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3d52ec",
   "metadata": {},
   "source": [
    "# Stage 1: model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f8c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models    import Model, load_model\n",
    "from tensorflow.keras.layers    import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses    import SparseCategoricalCrossentropy\n",
    "import math\n",
    "from collections                import Counter\n",
    "from sklearn.preprocessing      import LabelEncoder\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f95d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904fd879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "orig_train = \"/content/drive/MyDrive/Colab Notebooks/data_assign2/final_dataset/train\"\n",
    "orig_val   = \"/content/drive/MyDrive/Colab Notebooks/data_assign2/final_dataset/validation\"\n",
    "orig_test = \"/content/drive/MyDrive/Colab Notebooks/data_assign2/final_dataset/test\"\n",
    "\n",
    "out_train  = \"/content/drive/MyDrive/Colab Notebooks/data_assign2/final_dataset/train_small\"\n",
    "out_val    = \"/content/drive/MyDrive/Colab Notebooks/data_assign2/validation_small\"\n",
    "out_test    = \"/content/drive/MyDrive/Colab Notebooks/data_assign2/validation_small\"\n",
    "\n",
    "# resize images to 224 x 224\n",
    "def resize_and_save(input_dir, output_dir, size=(224, 224)):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for class_name in os.listdir(input_dir):\n",
    "        src_class = os.path.join(input_dir, class_name)\n",
    "        dst_class = os.path.join(output_dir, class_name)\n",
    "        if not os.path.isdir(src_class):\n",
    "            continue\n",
    "        os.makedirs(dst_class, exist_ok=True)\n",
    "        for fname in os.listdir(src_class):\n",
    "            src_path = os.path.join(src_class, fname)\n",
    "            dst_path = os.path.join(dst_class, fname)\n",
    "            try:\n",
    "                with Image.open(src_path) as img:\n",
    "                    img = img.convert('RGB')\n",
    "                    img = img.resize(size, resample=Image.LANCZOS)\n",
    "                    img.save(dst_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipped {src_path}: {e}\")\n",
    "\n",
    "resize_and_save(orig_train, out_train)\n",
    "resize_and_save(orig_val,   out_val)\n",
    "resize_and_save(orig_test,  out_test)\n",
    "\n",
    "print(\"all images resized to and saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987b1e58",
   "metadata": {},
   "source": [
    "The Stage 1 model (country classifier) for resnet50, the changes in order to have the code for effcientnet are written as comments in the code cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a8517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixed precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# paths\n",
    "TRAIN_DIR       = \"/content/drive/MyDrive/final_dataset/train\"\n",
    "VAL_DIR_GDRIVE  = \"/content/drive/MyDrive/final_dataset/validation\"\n",
    "CHECKPOINT_HEAD = \"/content/drive/MyDrive/full_finetune_head_resnet(0003_03).h5\"\n",
    "CHECKPOINT_FULL = \"/content/drive/MyDrive/full_finetune_final_resnet(0003_03).keras\"\n",
    "\n",
    "# copy validation locally for speed\n",
    "LOCAL_VAL_DIR = \"/tmp/validation_small\"\n",
    "if not os.path.exists(LOCAL_VAL_DIR):\n",
    "    shutil.copytree(VAL_DIR_GDRIVE, LOCAL_VAL_DIR)\n",
    "VAL_DIR = LOCAL_VAL_DIR\n",
    "\n",
    "# hyperparamters\n",
    "learning_rate = 0.0003\n",
    "batch_size = 32\n",
    "num_classes = 12\n",
    "dropout = 0.3\n",
    "input_shape = (224, 224, 3)\n",
    "weight_decay = 1e-4  # L2 regularization\n",
    "\n",
    "# build model with all layers trainable\n",
    "base = ResNet50(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "#base = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "x = GlobalAveragePooling2D()(base.output)\n",
    "x = Dense(512, activation='relu', kernel_regularizer=l2(weight_decay))(x)\n",
    "x = Dropout(dropout)(x)\n",
    "x = Dense(128, activation='relu', kernel_regularizer=l2(weight_decay))(x)\n",
    "x = Dropout(dropout)(x)\n",
    "outputs = Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "\n",
    "model = Model(inputs=base.input, outputs=outputs)\n",
    "\n",
    "# data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(224,224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# load all val in one batch\n",
    "count_gen = val_datagen.flow_from_directory(\n",
    "    VAL_DIR, target_size=(224,224),\n",
    "    batch_size=1, shuffle=False, class_mode='categorical'\n",
    ")\n",
    "num_val = count_gen.samples\n",
    "\n",
    "val_single = val_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(224,224),\n",
    "    batch_size=num_val,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "val_x, val_y    = val_single[0]\n",
    "val_y_idx       = val_single.classes\n",
    "class_indices   = val_single.class_indices\n",
    "\n",
    "# compute sample‐weights for imbalanced val\n",
    "val_counts = {\n",
    "    'argentina': 89, 'austria': 160, 'canada': 148, 'chile': 149,\n",
    "    'france': 128,   'iceland': 71,  'italy': 150,   'japan': 150,\n",
    "    'new_zealand':120,'norway':138,  'peru': 95,     'switzerland':183\n",
    "}\n",
    "total_val = sum(val_counts.values())\n",
    "n_classes = len(val_counts)\n",
    "class_weight_val = {\n",
    "    class_indices[name]: total_val/(n_classes*cnt)\n",
    "    for name,cnt in val_counts.items()\n",
    "}\n",
    "val_sample_weights = np.array([class_weight_val[i] for i in val_y_idx])\n",
    "\n",
    "# callbacks for head‐only stage\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    CHECKPOINT_HEAD, monitor='val_accuracy',\n",
    "    save_best_only=True, verbose=1\n",
    ")\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.2, patience=2, verbose=1\n",
    ")\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', patience=5,\n",
    "    restore_best_weights=True, verbose=1\n",
    ")\n",
    "\n",
    "# Stage 1: Train entire network end-to-end on clean data (no layer freezing)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_head = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=(val_x, val_y, val_sample_weights),\n",
    "    epochs=15,\n",
    "    callbacks=[checkpoint_cb, reduce_lr, early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# Stage 2: Continue fine-tuning end-to-end at lower LR (still no freezing)\n",
    "\n",
    "model.load_weights(CHECKPOINT_HEAD)\n",
    "\n",
    "# recompile with smaller LR\n",
    "model.compile(\n",
    "    optimizer=Adam(0.00003),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "checkpoint_full = ModelCheckpoint(\n",
    "    CHECKPOINT_FULL, monitor='val_accuracy',\n",
    "    save_best_only=True, verbose=1\n",
    ")\n",
    "\n",
    "history_full = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=(val_x, val_y, val_sample_weights),\n",
    "    epochs=5,\n",
    "    callbacks=[checkpoint_full, reduce_lr, early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# final evaluation\n",
    "val_pred_idx = np.argmax(model.predict(val_x, batch_size=32), axis=1)\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(val_y_idx, val_pred_idx))\n",
    "print(classification_report(val_y_idx, val_pred_idx,\n",
    "                            target_names=list(class_indices.keys())))\n",
    "\n",
    "# save histories (including training accuracy)\n",
    "pd.DataFrame(history_head.history).to_csv(\n",
    "    \"/content/drive/MyDrive/history_head_full_resnet(0003_03).csv\",\n",
    "    index=False\n",
    ")\n",
    "pd.DataFrame(history_full.history).to_csv(\n",
    "    \"/content/drive/MyDrive/history_full_finetune_resnet(0003_03).csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90989a53",
   "metadata": {},
   "source": [
    "# Stage 2: 12 country heads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17ce6d4",
   "metadata": {},
   "source": [
    "Stage 2 model (Geocell Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a417d955",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE   = \"/content/drive/MyDrive/Colab Notebooks/Advanced Analytics/data_assign2\"\n",
    "TRAIN_CSV   = f\"{BASE}/geocell_train.csv\"\n",
    "VAL_CSV     = f\"{BASE}/geocell_val.csv\"\n",
    "CENT_CSV    = f\"{BASE}/geocell_centroids.csv\"\n",
    "COUNTRY_MODEL = f\"{BASE}/checkpoints/best_result.keras\"\n",
    "HEADS_DIR     = f\"{BASE}/checkpointscountry_heads\"\n",
    "IMG_SIZE   = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "df_val   = pd.read_csv(  VAL_CSV)\n",
    "df_cent  = pd.read_csv(CENT_CSV).set_index(\"geocell_id\")\n",
    "\n",
    "for df in (df_train, df_val):\n",
    "    df[\"filepath\"] = (df[\"filepath\"]\n",
    "        .str.replace(\"\\\\\\\\\",\"/\",regex=False)\n",
    "        .str.replace(r\"^final_dataset/train\",\n",
    "                    f\"{BASE}/train_small\",regex=True)\n",
    "        .str.replace(r\"^final_dataset/validation\",\n",
    "                    f\"{BASE}/validation_small\",regex=True)\n",
    "        .str.replace(\"\\\\\\\\\",\"/\",regex=True)\n",
    "    )\n",
    "\n",
    "df_val  [\"filepath\"] = df_val [\"filepath\"].str.replace(\"\\\\\\\\\", \"/\", regex=True)\n",
    "df_train [\"filepath\"] = df_train [\"filepath\"].str.replace(\"\\\\\\\\\", \"/\", regex=True)\n",
    "\n",
    "# 0) Common: load & freeze country backbone\n",
    "stage1   = load_model(COUNTRY_MODEL)\n",
    "for layer in stage1.layers:\n",
    "    layer.trainable = False\n",
    "base_feat = stage1.layers[-2].output\n",
    "# for effcicientnet: base_feat = stage1.layers[-6].output\n",
    "\n",
    "# where to save each head + encoder\n",
    "OUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/Advanced Analytics/data_assign2/checkpointscountry_heads\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# 1) loop per country\n",
    "for country in le_c.classes_:\n",
    "    print(f\"\\n--- Training head for {country} ---\")\n",
    "\n",
    "    # a) subset\n",
    "    df_tr_ctry = df_train[df_train.country == country].copy()\n",
    "    df_va_ctry = df_val  [df_val.country   == country].copy()\n",
    "    if len(df_tr_ctry)==0 or len(df_va_ctry)==0:\n",
    "        continue\n",
    "\n",
    "    # b)  merge rare geoells (<150 samples) to nearest neighbor\n",
    "    counts = Counter(df_tr_ctry[\"geocell_id\"])\n",
    "    rare   = {g for g,c in counts.items() if c < 150}\n",
    "    common = [g for g,c in counts.items() if c >= 150]\n",
    "\n",
    "    # get centroids\n",
    "    cent = df_cent.loc[list(rare)+common, ['centroid_lat','centroid_lon']]\n",
    "    def hav(lat1,lon1,lat2,lon2):\n",
    "        φ1,φ2 = math.radians(lat1), math.radians(lat2)\n",
    "        dφ    = math.radians(lat2-lat1)\n",
    "        dλ    = math.radians(lon2-lon1)\n",
    "        a = math.sin(dφ/2)**2 + math.cos(φ1)*math.cos(φ2)*math.sin(dλ/2)**2\n",
    "        return 2*6371*math.atan2(math.sqrt(a),math.sqrt(1-a))\n",
    "\n",
    "    merge_map = {}\n",
    "    for r in rare:\n",
    "      lat0, lon0 = cent.loc[r]\n",
    "      nn = min(common, key=lambda g: hav(\n",
    "        lat0, lon0,\n",
    "        cent.loc[g, 'centroid_lat'],\n",
    "        cent.loc[g, 'centroid_lon']))\n",
    "      merge_map[r] = nn\n",
    "\n",
    "# simulate merge on train only, no mutation yet\n",
    "    merged_train = df_tr_ctry[\"geocell_id\"].map(lambda g: merge_map.get(g, g))\n",
    "    unique_after = merged_train.nunique()\n",
    "\n",
    "    if unique_after >= 2:\n",
    "    # apply on train and val\n",
    "        print(f\"merging {len(rare)} rare cells {unique_after} total classes\")\n",
    "        df_tr_ctry[\"geocell_id\"] = merged_train\n",
    "        df_va_ctry[\"geocell_id\"] = df_va_ctry[\"geocell_id\"].map(lambda g: merge_map.get(g, g))\n",
    "    else:\n",
    "    # skip entirely\n",
    "        print(f\"  → skipping merge (would leave only {unique_after} class)\")\n",
    "\n",
    "# now encode & build class weights\n",
    "    le_g_ctry         = LabelEncoder().fit(df_tr_ctry[\"geocell_id\"])\n",
    "    df_tr_ctry[\"g_lbl\"] = le_g_ctry.transform(df_tr_ctry[\"geocell_id\"])\n",
    "    df_va_ctry[\"g_lbl\"] = le_g_ctry.transform(df_va_ctry[\"geocell_id\"])\n",
    "    n_cells           = len(le_g_ctry.classes_)\n",
    "\n",
    "    cnts = Counter(df_tr_ctry[\"g_lbl\"])\n",
    "    total = sum(cnts.values())\n",
    "    class_weight = {lbl: total/(n_cells*c) for lbl,c in cnts.items()}\n",
    "\n",
    "    # c) dataset with augmentation\n",
    "    def make_ds(df, shuffle=True):\n",
    "        paths  = df[\"filepath\"].values\n",
    "        lbls   = df[\"g_lbl\"].values.astype(np.int32)\n",
    "        ds     = tf.data.Dataset.from_tensor_slices((paths,lbls))\n",
    "        if shuffle: ds = ds.shuffle(len(df))\n",
    "        def _load(p,l):\n",
    "            img = tf.io.read_file(p)\n",
    "            img = tf.image.decode_jpeg(img,3)\n",
    "            img = tf.image.resize(img,[IMG_SIZE,IMG_SIZE])\n",
    "            img = tf.image.random_flip_left_right(img)\n",
    "            img = tf.image.random_brightness(img,0.2)\n",
    "            img = preprocess_input(img)\n",
    "            return img, l\n",
    "        return ds.map(_load, tf.data.AUTOTUNE)\\\n",
    "                 .batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    ds_tr = make_ds(df_tr_ctry, shuffle=True)\n",
    "    ds_va = make_ds(df_va_ctry, shuffle=False)\n",
    "\n",
    "    # d) unfreeze last conv block\n",
    "    for layer in stage1.layers[-10:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # e) build & compile head with Dropout\n",
    "    x    = Dropout(0.5, name=f\"dropout_{country}\")(base_feat)\n",
    "    head = Dense(n_cells, activation=\"softmax\", name=f\"gc_{country}\")(x)\n",
    "    model_ct = Model(stage1.input, head, name=f\"model_{country}\")\n",
    "    model_ct.compile(\n",
    "        optimizer=Adam(1e-5),\n",
    "        loss=SparseCategoricalCrossentropy(),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    # f) train\n",
    "    ckpt = os.path.join(OUT_DIR, f\"head_{country}.keras\")\n",
    "    hist = model_ct.fit(\n",
    "        ds_tr,\n",
    "        validation_data=ds_va,\n",
    "        epochs=20,\n",
    "        class_weight=class_weight,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor=\"val_accuracy\", factor=0.5, patience=2, mode=\"max\"),\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_accuracy\", patience=6, restore_best_weights=True, mode=\"max\")\n",
    "        ],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # g) report & save\n",
    "    ta = hist.history[\"accuracy\"][-1]\n",
    "    va = hist.history[\"val_accuracy\"][-1]\n",
    "    print(f\"{country}: train={ta:.2%}  val={va:.2%}\")\n",
    "\n",
    "    ckpt       = os.path.join(OUT_DIR, f\"head_{country}.keras\")\n",
    "    enc_path   = os.path.join(OUT_DIR, f\"le_g_{country}.pkl\")\n",
    "    merge_path = os.path.join(OUT_DIR, f\"merge_map_{country}.pkl\")\n",
    "\n",
    "    model_ct.save(ckpt)\n",
    "    with open(enc_path, \"wb\") as f:\n",
    "        pickle.dump(le_g_ctry, f)\n",
    "    with open(merge_path, \"wb\") as f:\n",
    "        pickle.dump(merge_map, f)\n",
    "\n",
    "    print(f\"saved: {ckpt}, {enc_path}, {merge_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ea5440",
   "metadata": {},
   "source": [
    "# Stage 3: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5e8b9c",
   "metadata": {},
   "source": [
    "Stage 3 Model (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3629c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Hyperparameters\n",
    "IMG_SIZE    = 224\n",
    "BATCH_SIZE  = 32\n",
    "EPOCHS      = 20\n",
    "LR          = 3e-4\n",
    "\n",
    "# 2) load Stage‐1 and rebuild country encoder\n",
    "stage1 = tf.keras.models.load_model(COUNTRY_MODEL, compile=False)\n",
    "le_c   = LabelEncoder().fit(df_train[\"country\"])\n",
    "\n",
    "\n",
    "# 3) load all 12 heads + encoders + merge_maps into dicts\n",
    "heads      = {}\n",
    "le_gs      = {}\n",
    "merge_maps = {}\n",
    "for country in le_c.classes_:\n",
    "    hpth = os.path.join(HEADS_DIR, f\"head_{country}.keras\")\n",
    "    epth = os.path.join(HEADS_DIR, f\"le_g_{country}.pkl\")\n",
    "    mpth = os.path.join(HEADS_DIR, f\"merge_map_{country}.pkl\")\n",
    "    if os.path.exists(hpth):\n",
    "        heads[country]      = tf.keras.models.load_model(hpth, compile=False)\n",
    "        le_gs[country]      = pickle.load(open(epth,\"rb\"))\n",
    "        merge_maps[country] = pickle.load(open(mpth,\"rb\"))\n",
    "\n",
    "\n",
    "# 4) apply country-specific merges to build a global `geocell_merge`\n",
    "def apply_merge(df):\n",
    "    df = df.copy()\n",
    "    df[\"geocell_merge\"] = df.apply(\n",
    "      lambda r: merge_maps.get(r[\"country\"],{}).get(r[\"geocell_id\"], r[\"geocell_id\"]),\n",
    "      axis=1\n",
    "    )\n",
    "    return df\n",
    "\n",
    "df_train = apply_merge(df_train)\n",
    "df_val   = apply_merge(df_val)\n",
    "\n",
    "\n",
    "# 5) re-encode merged geocells and build centroids tensor\n",
    "le_g = LabelEncoder().fit(df_train[\"geocell_merge\"])\n",
    "df_train[\"geocell_lbl\"] = le_g.transform(df_train[\"geocell_merge\"])\n",
    "df_val  [\"geocell_lbl\"] = le_g.transform(df_val[\"geocell_merge\"])\n",
    "\n",
    "# grab centroids in the same order as le_g.classes_\n",
    "centroids = df_cent.loc[le_g.classes_, [\"centroid_lat\",\"centroid_lon\"]].values\n",
    "centroids_tensor = tf.constant(centroids, dtype=tf.float32)  # shape [G,2]\n",
    "\n",
    "\n",
    "# 6) build regression tf.data pipelines\n",
    "def make_reg_ds(df, shuffle=True):\n",
    "    paths = df[\"filepath\"].values\n",
    "    g_lbl = df[\"geocell_lbl\"].values.astype(np.int32)\n",
    "    lats  = df[\"lat\"].values.astype(np.float32)\n",
    "    lons  = df[\"lon\"].values.astype(np.float32)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, g_lbl, lats, lons))\n",
    "    if shuffle: ds = ds.shuffle(len(df))\n",
    "    def _load(p, g, la, lo):\n",
    "        img = tf.io.read_file(p)\n",
    "        img = tf.image.decode_jpeg(img,3)\n",
    "        img = tf.image.resize(img, [IMG_SIZE,IMG_SIZE])\n",
    "        img = preprocess_input(img)\n",
    "        cen = tf.gather(centroids_tensor, g)            # [2]\n",
    "        res = tf.stack([la, lo]) - cen                  # [2]\n",
    "        return img, res\n",
    "    return ds.map(_load, tf.data.AUTOTUNE)\\\n",
    "             .batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_reg_ds = make_reg_ds(df_train, shuffle=True)\n",
    "val_reg_ds   = make_reg_ds(df_val,   shuffle=False)\n",
    "\n",
    "\n",
    "# 7) build and compile the residual MLP\n",
    "# reuse the frozen stage1 backbone up to its penultimate layer\n",
    "feat = stage1.layers[-2].output\n",
    "\n",
    "r = Dense(512, activation=\"relu\", name=\"dense_reg_1\")(feat)\n",
    "r = Dense(256, activation=\"relu\", name=\"dense_reg_2\")(r)\n",
    "res_out = Dense(2, name=\"delta\")(r)\n",
    "\n",
    "reg_model = Model(inputs=stage1.input, outputs=res_out)\n",
    "reg_model.compile(\n",
    "    optimizer=Adam(LR),\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "\n",
    "# 8) train\n",
    "reg_model.fit(\n",
    "    train_reg_ds,\n",
    "    validation_data=val_reg_ds,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "      tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3),\n",
    "      tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# 9) inference helper: country -> head -> centroid -> residual\n",
    "\n",
    "def predict_coord(img):\n",
    "    # a) country\n",
    "    c_logits = stage1(tf.expand_dims(img,0), training=False)\n",
    "    c_idx    = tf.argmax(c_logits, axis=1)[0].numpy()\n",
    "    country  = le_c.classes_[c_idx]\n",
    "\n",
    "    # b) geocell head\n",
    "    head     = heads[country]\n",
    "    g_logits = head(tf.expand_dims(img,0), training=False)\n",
    "    g_idx    = tf.argmax(g_logits, axis=1)[0].numpy()\n",
    "    raw_cell = le_gs[country].classes_[g_idx]\n",
    "\n",
    "    # c) apply merge\n",
    "    merged   = merge_maps[country].get(raw_cell, raw_cell)\n",
    "    geo_idx  = np.where(le_g.classes_ == merged)[0][0]\n",
    "\n",
    "    # d) centroid + residual\n",
    "    cen      = centroids[geo_idx]\n",
    "    delta    = reg_model(tf.expand_dims(img,0), training=False).numpy()[0]\n",
    "    return cen + delta\n",
    "\n",
    "\n",
    "reg_model.save(\"/content/drive/MyDrive/model stage 1/resnet/model(0003_03)/regressor_savedmodel.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6162ea7f",
   "metadata": {},
   "source": [
    "# Results test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9ba006",
   "metadata": {},
   "source": [
    "The code predicts country and geocell from test images, maps them to coordinates, and evaluates accuracy and location error per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0744b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load heads, encoders, merge maps\n",
    "heads, encoders, merge_maps = {}, {}, {}\n",
    "for c in le_c.classes_:\n",
    "    hp = os.path.join(HEADS_DIR, f\"head_{c}.keras\")\n",
    "    ep = os.path.join(HEADS_DIR, f\"le_g_{c}.pkl\")\n",
    "    mp = os.path.join(HEADS_DIR, f\"merge_map_{c}.pkl\")\n",
    "    if os.path.exists(hp):\n",
    "        heads[c]      = load_model(hp)\n",
    "        encoders[c]   = pickle.load(open(ep,\"rb\"))\n",
    "        merge_maps[c] = pickle.load(open(mp,\"rb\"))\n",
    "\n",
    "# helper to predict batch\n",
    "def predict_batch(paths):\n",
    "    imgs = []\n",
    "    for p in paths:\n",
    "        x = tf.io.read_file(p)\n",
    "        x = tf.image.decode_jpeg(x,3)\n",
    "        x = tf.image.resize(x,[IMG_SIZE,IMG_SIZE])\n",
    "        imgs.append(tf.keras.applications.resnet50.preprocess_input(x))\n",
    "    batch = tf.stack(imgs)\n",
    "    c_logits = stage1(batch, training=False).numpy()\n",
    "    c_idx    = np.argmax(c_logits,axis=1)\n",
    "    c_pred   = le_c.classes_[c_idx]\n",
    "\n",
    "    g_pred = []\n",
    "    for img, c in zip(batch, c_pred):\n",
    "        head = heads.get(c)\n",
    "        enc  = encoders.get(c)\n",
    "        if head is None:\n",
    "            g_pred.append(None)\n",
    "        else:\n",
    "            gl = head(img[None],training=False).numpy()\n",
    "            gi = np.argmax(gl,axis=1)[0]\n",
    "            g_pred.append(enc.classes_[gi])\n",
    "    return c_pred, g_pred\n",
    "\n",
    "# predictions on test set\n",
    "all_true_c, all_pred_c = [], []\n",
    "all_true_g, all_pred_g = [], []\n",
    "\n",
    "for i in range(0, len(df_test), BATCH_SIZE):\n",
    "    batch = df_test.iloc[i:i+BATCH_SIZE]\n",
    "    pc, pg = predict_batch(batch.filepath.tolist())\n",
    "    all_true_c.extend(batch.country)\n",
    "    all_true_g.extend(batch.geocell_id)\n",
    "    all_pred_c.extend(pc)\n",
    "    all_pred_g.extend(pg)\n",
    "\n",
    "# merge maps\n",
    "true_merged = [\n",
    "    merge_maps[c].get(g, g)\n",
    "    for c, g in zip(all_true_c, all_true_g)\n",
    "]\n",
    "\n",
    "# evaluation dataframe\n",
    "df_map = pd.DataFrame({\n",
    "    \"true_country\": all_true_c,\n",
    "    \"pred_country\": all_pred_c,\n",
    "    \"true_geocell\": true_merged,\n",
    "    \"pred_geocell\": all_pred_g\n",
    "})\n",
    "\n",
    "# centroid coordinates\n",
    "cent = df_cent[[\"centroid_lat\",\"centroid_lon\"]].to_dict(\"index\")\n",
    "df_map[\"true_coord\"] = df_map[\"true_geocell\"].map(lambda g: tuple(cent[g].values()))\n",
    "df_map[\"pred_coord\"] = df_map[\"pred_geocell\"].map(lambda g: tuple(cent[g].values()))\n",
    "\n",
    "# haverisne\n",
    "def haversine_km(p1,p2):\n",
    "    φ1,φ2 = np.radians(p1[0]), np.radians(p2[0])\n",
    "    dφ    = np.radians(p2[0]-p1[0])\n",
    "    dλ    = np.radians(p2[1]-p1[1])\n",
    "    a = np.sin(dφ/2)**2 + np.cos(φ1)*np.cos(φ2)*np.sin(dλ/2)**2\n",
    "    return 2*6371*np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "\n",
    "# errors\n",
    "df_map[\"lat_err\"] = df_map.apply(lambda r: abs(r[\"pred_coord\"][0]-r[\"true_coord\"][0]), axis=1)\n",
    "df_map[\"lon_err\"] = df_map.apply(lambda r: abs(r[\"pred_coord\"][1]-r[\"true_coord\"][1]), axis=1)\n",
    "df_map[\"geo_err\"] = df_map.apply(lambda r: haversine_km(r[\"true_coord\"],r[\"pred_coord\"]), axis=1)\n",
    "df_map[\"cty_corr\"]  = (df_map.pred_country==df_map.true_country).astype(int)\n",
    "df_map[\"cell_corr\"] = (df_map.pred_geocell ==df_map.true_geocell).astype(int)\n",
    "\n",
    "# group results\n",
    "per_ctry = df_map.groupby(\"true_country\").agg(\n",
    "    lat_MAE    = (\"lat_err\",    \"mean\"),\n",
    "    lon_MAE    = (\"lon_err\",    \"mean\"),\n",
    "    geo_MAE_km = (\"geo_err\",    \"mean\"),\n",
    "    country_acc= (\"cty_corr\",   \"mean\"),\n",
    "    geocell_acc= (\"cell_corr\",  \"mean\")\n",
    ").round(4)\n",
    "\n",
    "print(per_ctry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2b7c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# coordinates from df_map\n",
    "true_lats = np.array([lat for lat, lon in df_map['true_coord']])\n",
    "true_lons = np.array([lon for lat, lon in df_map['true_coord']])\n",
    "pred_lats = np.array([lat for lat, lon in df_map['pred_coord']])\n",
    "pred_lons = np.array([lon for lat, lon in df_map['pred_coord']])\n",
    "\n",
    "# latitute and longitude mae\n",
    "lat_mae = np.mean(np.abs(pred_lats - true_lats))\n",
    "lon_mae = np.mean(np.abs(pred_lons - true_lons))\n",
    "\n",
    "# global mae with haversine\n",
    "def haversine_km(p1, p2):\n",
    "    lat1, lon1 = p1\n",
    "    lat2, lon2 = p2\n",
    "    φ1, φ2 = np.radians(lat1), np.radians(lat2)\n",
    "    dφ = np.radians(lat2 - lat1)\n",
    "    dλ = np.radians(lon2 - lon1)\n",
    "    a = np.sin(dφ / 2)**2 + np.cos(φ1) * np.cos(φ2) * np.sin(dλ / 2)**2\n",
    "    return 2 * 6371 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "errors_km = [\n",
    "    haversine_km(tc, pc)\n",
    "    for tc, pc in zip(df_map['true_coord'], df_map['pred_coord'])\n",
    "]\n",
    "global_mae_km = np.mean(errors_km)\n",
    "\n",
    "# use geo_err for median if possible\n",
    "if \"geo_err\" in df_map.columns:\n",
    "    median_error = df_map[\"geo_err\"].median()\n",
    "else:\n",
    "    median_error = np.median(errors_km)\n",
    "\n",
    "# classification accuracy\n",
    "country_acc = accuracy_score(df_map['true_country'], df_map['pred_country'])\n",
    "geocell_acc = accuracy_score(df_map['true_geocell'], df_map['pred_geocell'])\n",
    "\n",
    "# summary results\n",
    "print(\"===== Global Evaluation Summary =====\")\n",
    "print(f\"Latitude MAE:            {lat_mae:.5f}°\")\n",
    "print(f\"Longitude MAE:           {lon_mae:.5f}°\")\n",
    "print(f\"Coordinate MAE (km):     {global_mae_km:.2f} km\")\n",
    "print(f\"Overall Median Error:    {median_error:.2f} km\")\n",
    "print(f\"Country Accuracy:        {country_acc:.4f}\")\n",
    "print(f\"Geocell Accuracy:        {geocell_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c24e1c",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793b869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 3 easiest and 3 hardest images to predict for model\n",
    "model = COUNTRY_MODEL\n",
    "\n",
    "# filepaths from df_test\n",
    "df_map[\"filepath\"] = df_test[\"filepath\"].values\n",
    "\n",
    "# helper to filter top N rows with unique true coordinates\n",
    "def top_unique(df, column, n=5, largest=True):\n",
    "    df_sorted = df.sort_values(by=column, ascending=not largest)\n",
    "    unique_coords = set()\n",
    "    selected = []\n",
    "    for _, row in df_sorted.iterrows():\n",
    "        if row[\"true_coord\"] not in unique_coords:\n",
    "            selected.append(row)\n",
    "            unique_coords.add(row[\"true_coord\"])\n",
    "        if len(selected) == n:\n",
    "            break\n",
    "    return pd.DataFrame(selected)\n",
    "\n",
    "# hardest and easiest based on geo_err, ensuring unique true_coords\n",
    "hardest = top_unique(df_map, \"geo_err\", n=3, largest=True)[[\"filepath\", \"true_coord\", \"pred_coord\", \"geo_err\"]]\n",
    "easiest = top_unique(df_map, \"geo_err\", n=3, largest=False)[[\"filepath\", \"true_coord\", \"pred_coord\", \"geo_err\"]]\n",
    "\n",
    "# full titles seperately\n",
    "def print_image_titles(df, label):\n",
    "    print(f\"\\n=== {label} ===\")\n",
    "    for i, row in df.iterrows():\n",
    "        print(f\"{i+1}. Error: {row['geo_err']:.1f} km | True: {row['true_coord']} | Pred: {row['pred_coord']}\")\n",
    "\n",
    "print_image_titles(hardest, \"3 Hardest Images\")\n",
    "print_image_titles(easiest, \"3 Easiest Images\")\n",
    "\n",
    "# images\n",
    "def show_images(df, title):\n",
    "    n = len(df)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(3*n, 3))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    for ax, (_, row) in zip(axes, df.iterrows()):\n",
    "        img = Image.open(row[\"filepath\"])\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"{row['geo_err']:.1f} km\")\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_images(hardest, \"3 Hardest Images\")\n",
    "show_images(easiest, \"3 Easiest Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da148584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention mapping\n",
    "# only keep non‐perfect predictions\n",
    "df_nonzero = df_map[df_map.geo_err > 1e-3]\n",
    "\n",
    "# recompute parts on that subset\n",
    "q1, q2, q3, q4 = np.percentile(df_nonzero.geo_err, [25, 50, 75, 85])\n",
    "\n",
    "# sample from the middle two bins\n",
    "mid_low  = df_nonzero[(df_nonzero.geo_err>=q1)&(df_nonzero.geo_err<q2)].sample(2)\n",
    "mid_high = df_nonzero[(df_nonzero.geo_err>=q2)&(df_nonzero.geo_err<q3)].sample(2)\n",
    "high = df_nonzero[(df_nonzero.geo_err>=q3)&(df_nonzero.geo_err<q4)].sample(3)\n",
    "\n",
    "to_inspect = pd.concat([mid_low, mid_high])\n",
    "show_cam_row(to_inspect, \"Attention Mapping\", stage1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
